{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport skimage.io\nimport os \nimport tqdm\nimport glob\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle, resample\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom tensorflow.keras.applications import ResNet50, DenseNet121,EfficientNetB1\nfrom tensorflow.keras.utils import to_categorical\nfrom keras import optimizers\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom keras.applications.nasnet import NASNetLarge, NASNetMobile\nfrom keras.callbacks import Callback,ModelCheckpoint,ReduceLROnPlateau\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,Dropout,Input, UpSampling2D, GlobalAveragePooling2D,concatenate,Conv2DTranspose\nfrom keras.models import Sequential,load_model,Model\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.losses import categorical_crossentropy\nimport random\nimport keras.backend as K","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:29:41.943172Z","iopub.execute_input":"2023-10-29T11:29:41.943428Z","iopub.status.idle":"2023-10-29T11:29:53.029000Z","shell.execute_reply.started":"2023-10-29T11:29:41.943405Z","shell.execute_reply":"2023-10-29T11:29:53.028218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import sys\n# import platform\n# print(sys.version)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pkg_resources\n# installed_packages = pkg_resources.working_set\n# for package in installed_packages:\n#     print(f\"{package.key}=={package.version}\")\n","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/severstal-steel-defect-detection'\ntrain_df = pd.read_csv('/kaggle/input/severstal-steel-defect-detection/train.csv')\ndata_folder = '/kaggle/input/severstal-steel-defect-detection/train_images'\ntest_folder = '/kaggle/input/severstal-steel-defect-detection/test_images'\ninput_shape = (128,128)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:30:02.958722Z","iopub.execute_input":"2023-10-29T11:30:02.959943Z","iopub.status.idle":"2023-10-29T11:30:03.315508Z","shell.execute_reply.started":"2023-10-29T11:30:02.959895Z","shell.execute_reply":"2023-10-29T11:30:03.314719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = train_df[train_df.ClassId == 1]\ndf2 = train_df[train_df.ClassId == 2]\ndf3 = train_df[train_df.ClassId == 3]\ndf4 = train_df[train_df.ClassId == 4]\nprint(df1.shape, df2.shape, df3.shape, df4.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:30:06.672837Z","iopub.execute_input":"2023-10-29T11:30:06.673246Z","iopub.status.idle":"2023-10-29T11:30:06.690221Z","shell.execute_reply.started":"2023-10-29T11:30:06.673215Z","shell.execute_reply":"2023-10-29T11:30:06.689241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3_undersampled = resample(df3, replace=False, n_samples=1500, random_state=42)  \ndf1_oversampled = resample(df1, replace=True, n_samples=1500, random_state=42)  \ndf2_oversampled = resample(df2, replace=True, n_samples=1500, random_state=42)  \ndf4_oversampled = resample(df4, replace=True, n_samples=1500, random_state=42)  \n\nbalanced_data = pd.concat([df1_oversampled, df2_oversampled, df3_undersampled, df4_oversampled])\nbalanced_data = balanced_data.sample(frac=1, random_state=42)\nbalanced_data","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:30:10.044706Z","iopub.execute_input":"2023-10-29T11:30:10.045659Z","iopub.status.idle":"2023-10-29T11:30:10.077593Z","shell.execute_reply.started":"2023-10-29T11:30:10.045612Z","shell.execute_reply":"2023-10-29T11:30:10.076690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_decode(mask_rle: str = '', shape: tuple = (256, 1600)):\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape, order='F')\n\ndef make_mask(balanced_data: pd.DataFrame, image_name: str='img.jpg', shape: tuple = (256, 1600)):\n    encoded_masks = balanced_data.loc[balanced_data['ImageId'] == image_name, 'EncodedPixels']\n    masks = np.zeros((shape[0], shape[1]), dtype=np.float32)\n    for idx, label in enumerate(encoded_masks.values):\n        if label is not np.nan:\n            mask = rle_decode(label)\n            masks[:, :] = mask\n    return masks\n\ndef get_img(x, folder: str='Train_images'):\n    image_path = os.path.join(data_folder, x)\n    print(image_path)\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:30:15.312556Z","iopub.execute_input":"2023-10-29T11:30:15.312825Z","iopub.status.idle":"2023-10-29T11:30:15.337774Z","shell.execute_reply.started":"2023-10-29T11:30:15.312802Z","shell.execute_reply":"2023-10-29T11:30:15.336915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_list = []\nfor file in os.listdir(test_folder):\n    imgpath = os.path.join(test_folder, file)\n    imgtest = cv2.imread(imgpath)\n    imgtest = cv2.resize(imgtest, input_shape)\n    test_list.append(imgtest)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:30:19.058225Z","iopub.execute_input":"2023-10-29T11:30:19.058565Z","iopub.status.idle":"2023-10-29T11:31:44.237686Z","shell.execute_reply.started":"2023-10-29T11:30:19.058539Z","shell.execute_reply":"2023-10-29T11:31:44.236820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_list = balanced_data[\"ImageId\"].tolist()\nlabel_list = balanced_data[\"ClassId\"].tolist()\nimg_list[0:5], label_list[0:5]","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:32:52.683765Z","iopub.execute_input":"2023-10-29T11:32:52.684650Z","iopub.status.idle":"2023-10-29T11:32:52.692040Z","shell.execute_reply.started":"2023-10-29T11:32:52.684614Z","shell.execute_reply":"2023-10-29T11:32:52.691050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_list = []\nmask_list = []\nfor img in img_list:\n    image = get_img(img)\n    image = cv2.resize(image, input_shape)\n    mask = make_mask(balanced_data, img)\n    mask = cv2.resize(mask, input_shape)\n    image_list.append(image)\n    mask_list.append(mask)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:33:06.513179Z","iopub.execute_input":"2023-10-29T11:33:06.514068Z","iopub.status.idle":"2023-10-29T11:34:46.696353Z","shell.execute_reply.started":"2023-10-29T11:33:06.514033Z","shell.execute_reply":"2023-10-29T11:34:46.695413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.array(image_list)\ny = np.array(mask_list)\nencoded = LabelEncoder()\nz=encoded.fit_transform(label_list)\nz=to_categorical(z)\nprint(X.shape, y.shape, z.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:34:59.412660Z","iopub.execute_input":"2023-10-29T11:34:59.413546Z","iopub.status.idle":"2023-10-29T11:34:59.634071Z","shell.execute_reply.started":"2023-10-29T11:34:59.413513Z","shell.execute_reply":"2023-10-29T11:34:59.633088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val, z_train, z_val = train_test_split(X, y, z, test_size=0.2, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:35:02.476619Z","iopub.execute_input":"2023-10-29T11:35:02.477603Z","iopub.status.idle":"2023-10-29T11:35:02.686735Z","shell.execute_reply.started":"2023-10-29T11:35:02.477566Z","shell.execute_reply":"2023-10-29T11:35:02.685693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = 1\ninputs = tf.keras.layers.Input((128, 128, 3))\n\nc1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\nc1 = tf.keras.layers.Dropout(0.1)(c1)\nc1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\nb1 = tf.keras.layers.BatchNormalization()(c1)\nr1 = tf.keras.layers.ReLU()(b1)\np1 = tf.keras.layers.MaxPooling2D((2, 2))(r1)\n\nc2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\nc2 = tf.keras.layers.Dropout(0.1)(c2)\nc2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\nb2 = tf.keras.layers.BatchNormalization()(c2)\nr2 = tf.keras.layers.ReLU()(b2)\np2 = tf.keras.layers.MaxPooling2D((2, 2))(r2)\n\nc3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\nc3 = tf.keras.layers.Dropout(0.2)(c3)\nc3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\nb3 = tf.keras.layers.BatchNormalization()(c3)\nr3 = tf.keras.layers.ReLU()(b3)\np3 = tf.keras.layers.MaxPooling2D((2, 2))(r3)\n\nc4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\nc4 = tf.keras.layers.Dropout(0.2)(c4)\nc4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\nb4 = tf.keras.layers.BatchNormalization()(c4)\nr4 = tf.keras.layers.ReLU()(b4)\np4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(r4)\n\nc5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\nb5 = tf.keras.layers.BatchNormalization()(c5)\nr5 = tf.keras.layers.ReLU()(b5)\nc5 = tf.keras.layers.Dropout(0.3)(r5)\nc5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n\nu6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\nu6 = tf.keras.layers.concatenate([u6, c4])\nu6 = tf.keras.layers.BatchNormalization()(u6)\nu6 = tf.keras.layers.ReLU()(u6)\n\nu7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(u6)\nu7 = tf.keras.layers.concatenate([u7, c3])\nu7 = tf.keras.layers.BatchNormalization()(u7)\nu7 = tf.keras.layers.ReLU()(u7)\n\nu8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(u7)\nu8 = tf.keras.layers.concatenate([u8, c2])\nu8 = tf.keras.layers.BatchNormalization()(u8)\nu8 = tf.keras.layers.ReLU()(u8)\n\nu9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(u8)\nu9 = tf.keras.layers.concatenate([u9, c1], axis=3)\nu9 = tf.keras.layers.BatchNormalization()(u9)\nu9 = tf.keras.layers.ReLU()(u9)\n\noutputs = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='sigmoid')(u9)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:35:05.577332Z","iopub.execute_input":"2023-10-29T11:35:05.577812Z","iopub.status.idle":"2023-10-29T11:35:10.319845Z","shell.execute_reply.started":"2023-10-29T11:35:05.577774Z","shell.execute_reply":"2023-10-29T11:35:10.318853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seg_model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\nseg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nlrd = ReduceLROnPlateau(monitor = 'val_loss',patience = 5,verbose = 1,factor = 0.50, min_lr = 1e-10)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:35:14.302696Z","iopub.execute_input":"2023-10-29T11:35:14.303744Z","iopub.status.idle":"2023-10-29T11:35:14.333697Z","shell.execute_reply.started":"2023-10-29T11:35:14.303684Z","shell.execute_reply":"2023-10-29T11:35:14.332817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seg_history = seg_model.fit(X_train, y_train, epochs =45, batch_size=32, validation_data=(X_val, y_val), callbacks=[lrd])","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:35:18.222911Z","iopub.execute_input":"2023-10-29T11:35:18.223282Z","iopub.status.idle":"2023-10-29T11:43:32.815846Z","shell.execute_reply.started":"2023-10-29T11:35:18.223252Z","shell.execute_reply":"2023-10-29T11:43:32.815050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display(display_list):\n    plt.figure(figsize=(20, 20))\n    title = ['Input image', 'True mask', 'Predicted mask']\n    for i in range(len(display_list)):\n        plt.subplot(1, len(display_list), i+1)\n        plt.title(title[i])\n        plt.imshow(display_list[i])\n        plt.axis('off')\n    plt.show()\n\ni = random.randint(0, len(X_val) - 1)\nsample_image = X_val[i]\nsample_mask = y_val[i]\nprediction = seg_model.predict(sample_image[np.newaxis, ...])[0]\npredicted_mask = (prediction > 0.5).astype(np.uint8)\ndisplay([sample_image, sample_mask, predicted_mask])","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:45:06.241163Z","iopub.execute_input":"2023-10-29T11:45:06.241867Z","iopub.status.idle":"2023-10-29T11:45:07.318127Z","shell.execute_reply.started":"2023-10-29T11:45:06.241832Z","shell.execute_reply":"2023-10-29T11:45:07.317239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = seg_model.predict(sample_image[np.newaxis, ...])[0]\nprint(tf.reduce_max(prediction))","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:05:01.200157Z","iopub.execute_input":"2023-10-25T07:05:01.200541Z","iopub.status.idle":"2023-10-25T07:05:01.275735Z","shell.execute_reply.started":"2023-10-25T07:05:01.200485Z","shell.execute_reply":"2023-10-25T07:05:01.274829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pkg_resources\n# installed_packages = pkg_resources.working_set\n# for package in installed_packages:\n#     print(f\"{package.key}=={package.version}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SAVE MODEL- 1","metadata":{}},{"cell_type":"code","source":"# #Code to save model weights\n# from keras.models import Model\n# seg_model.save(\"//kaggle/working/segmentation_model.h5\")\n\n# \"\"\"\n# #to load model\n# from keras.model import load_model\n# loaded_model= load_model(\"segmentation_model.h5\")\n# \"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from keras.models import Model\n# import tensorflow as tf\n\n# # Save the model in the TensorFlow SavedModel format\n# tf.saved_model.save(seg_model, \"//kaggle/working/segmentation_model.h5\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:05:24.059900Z","iopub.execute_input":"2023-10-25T07:05:24.060265Z","iopub.status.idle":"2023-10-25T07:05:30.596025Z","shell.execute_reply.started":"2023-10-25T07:05:24.060236Z","shell.execute_reply":"2023-10-25T07:05:30.595232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seg_model.get_config()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:45:16.445737Z","iopub.execute_input":"2023-10-29T11:45:16.446086Z","iopub.status.idle":"2023-10-29T11:45:16.510390Z","shell.execute_reply.started":"2023-10-29T11:45:16.446060Z","shell.execute_reply":"2023-10-29T11:45:16.509325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.experimental.export_saved_model(seg_model, '//kaggle/working/segmentation_model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:45:35.630047Z","iopub.execute_input":"2023-10-29T11:45:35.630731Z","iopub.status.idle":"2023-10-29T11:45:35.670644Z","shell.execute_reply.started":"2023-10-29T11:45:35.630703Z","shell.execute_reply":"2023-10-29T11:45:35.669232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seg_model.save('//kaggle/working/segmentation_model.tf')","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:47:13.871665Z","iopub.execute_input":"2023-10-29T11:47:13.872058Z","iopub.status.idle":"2023-10-29T11:47:20.762383Z","shell.execute_reply.started":"2023-10-29T11:47:13.872027Z","shell.execute_reply":"2023-10-29T11:47:20.761609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train=X_train/255\nx_val=X_val/255","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:47:30.206338Z","iopub.execute_input":"2023-10-29T11:47:30.206713Z","iopub.status.idle":"2023-10-29T11:47:30.972469Z","shell.execute_reply.started":"2023-10-29T11:47:30.206683Z","shell.execute_reply":"2023-10-29T11:47:30.971566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:47:48.455123Z","iopub.execute_input":"2023-10-29T11:47:48.456007Z","iopub.status.idle":"2023-10-29T11:48:01.575405Z","shell.execute_reply.started":"2023-10-29T11:47:48.455971Z","shell.execute_reply":"2023-10-29T11:48:01.574349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom efficientnet.tfkeras import EfficientNetB1\nclass_model = EfficientNetB1(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\nx_train = class_model.output\nx_train = GlobalAveragePooling2D()(x_train)\nx_train = Dense(512, activation='relu')(x_train)\nx_train = Dropout(0.2)(x_train)\nx_train = Dense(256, activation='relu')(x_train)\nx_train = Dropout(0.2)(x_train)\nx_train = Dense(128, activation='relu')(x_train)\nx_train = Dropout(0.2)(x_train)\nx_train = Dense(64, activation='relu')(x_train)\nx_train = Dropout(0.2)(x_train)\npredictions = Dense(4, activation='softmax')(x_train)\nclass_model = Model(inputs=class_model.input, outputs=predictions)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:48:25.823019Z","iopub.execute_input":"2023-10-29T11:48:25.823375Z","iopub.status.idle":"2023-10-29T11:48:29.348105Z","shell.execute_reply.started":"2023-10-29T11:48:25.823347Z","shell.execute_reply":"2023-10-29T11:48:29.347095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau\nlr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=5, min_lr=1e-8)\nclass_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:48:35.278915Z","iopub.execute_input":"2023-10-29T11:48:35.279588Z","iopub.status.idle":"2023-10-29T11:48:35.300203Z","shell.execute_reply.started":"2023-10-29T11:48:35.279553Z","shell.execute_reply":"2023-10-29T11:48:35.299333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='nearest'\n)\ntrain_generator = datagen.flow(X_train,z_train, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:48:38.873486Z","iopub.execute_input":"2023-10-29T11:48:38.874119Z","iopub.status.idle":"2023-10-29T11:48:39.219404Z","shell.execute_reply.started":"2023-10-29T11:48:38.874085Z","shell.execute_reply":"2023-10-29T11:48:39.218227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_history = class_model.fit(train_generator,epochs=35,validation_data=(x_val,z_val), batch_size=batch_size, verbose=1, callbacks=[lr_callback])","metadata":{"execution":{"iopub.status.busy":"2023-10-29T11:48:42.966418Z","iopub.execute_input":"2023-10-29T11:48:42.966950Z","iopub.status.idle":"2023-10-29T12:01:35.884572Z","shell.execute_reply.started":"2023-10-29T11:48:42.966917Z","shell.execute_reply":"2023-10-29T12:01:35.883766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pkg_resources\n# installed_packages = pkg_resources.working_set\n# for package in installed_packages:\n#     print(f\"{package.key}=={package.version}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SAVE MODEL- 2","metadata":{}},{"cell_type":"code","source":"# #Code to save model weights\n# from keras.models import Model\n# class_model.save(\"//kaggle/working/classification_model.h5\")\n\n# \"\"\"\n# #Code to load model weights\n# from keras.models import load_model\n# loaded_model=load_model(\"classification_model.h5\")\n# \"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_model.get_config()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T12:01:40.772355Z","iopub.execute_input":"2023-10-29T12:01:40.773179Z","iopub.status.idle":"2023-10-29T12:01:41.155306Z","shell.execute_reply.started":"2023-10-29T12:01:40.773143Z","shell.execute_reply":"2023-10-29T12:01:41.154370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tf.keras.experimental.export_saved_model(class_model, '\"//kaggle/working/classification_model.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_model.save('//kaggle/working/classification_model.tf')","metadata":{"execution":{"iopub.status.busy":"2023-10-29T12:02:21.483996Z","iopub.execute_input":"2023-10-29T12:02:21.484349Z","iopub.status.idle":"2023-10-29T12:03:10.212572Z","shell.execute_reply.started":"2023-10-29T12:02:21.484320Z","shell.execute_reply":"2023-10-29T12:03:10.211481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from keras.models import Model\n# import tensorflow as tf\n\n# # Save the model in the TensorFlow SavedModel format\n# tf.saved_model.save(class_model, \"//kaggle/working/classification_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:22:26.407377Z","iopub.execute_input":"2023-10-25T07:22:26.413741Z","iopub.status.idle":"2023-10-25T07:23:13.118376Z","shell.execute_reply.started":"2023-10-25T07:22:26.413708Z","shell.execute_reply":"2023-10-25T07:23:13.117263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = random.randint(0, len(X_val) - 1)\nsample_image = X_val[i]\nsample_mask = y_val[i]\nprediction = seg_model.predict(sample_image[np.newaxis, ...])[0]\npredicted_mask = (prediction > 0.5).astype(np.uint8)\nprediction_class = class_model.predict(sample_image[np.newaxis, ...])[0]\ndisplay([sample_image, sample_mask, predicted_mask])\nprint(\"Type defect: \" ,np.argmax(prediction_class))","metadata":{"execution":{"iopub.status.busy":"2023-10-29T12:05:34.725166Z","iopub.execute_input":"2023-10-29T12:05:34.725567Z","iopub.status.idle":"2023-10-29T12:05:37.972394Z","shell.execute_reply.started":"2023-10-29T12:05:34.725534Z","shell.execute_reply":"2023-10-29T12:05:37.971423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_test(display_list):\n    plt.figure(figsize=(15, 15))\n    title = ['Input image', 'Predicted mask']\n    for i in range(len(display_list)):\n        plt.subplot(1, len(display_list), i+1)\n        plt.title(title[i])\n        plt.imshow(display_list[i])\n        plt.axis('off')\n    plt.show()\n\nX_test = np.array(test_list)\ni = random.randint(0, len(X_test) - 1)\nsample_image = X_test[i]\nprediction = seg_model.predict(sample_image[np.newaxis, ...])[0]\npredicted_mask = (prediction > 0.5).astype(np.uint8)\nprediction_class = class_model.predict(sample_image[np.newaxis, ...])[0]\ndisplay_test([sample_image, predicted_mask])\nprint(\"Type defect: \" ,np.argmax(prediction_class))","metadata":{"execution":{"iopub.status.busy":"2023-10-29T12:05:44.507954Z","iopub.execute_input":"2023-10-29T12:05:44.508312Z","iopub.status.idle":"2023-10-29T12:05:45.034816Z","shell.execute_reply.started":"2023-10-29T12:05:44.508286Z","shell.execute_reply":"2023-10-29T12:05:45.033738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_training_history(history):\n    \n    train_accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n    train_loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    plt.subplot(1, 2, 1)  \n    plt.plot(range(1, len(train_accuracy) + 1), train_accuracy, label='Train')\n    plt.plot(range(1, len(val_accuracy) + 1), val_accuracy, label='Validation')\n    plt.title('Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)  \n    plt.plot(range(1, len(train_loss) + 1), train_loss, label='Train')\n    plt.plot(range(1, len(val_loss) + 1), val_loss, label='Validation')\n    plt.title('Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T12:05:58.533942Z","iopub.execute_input":"2023-10-29T12:05:58.534309Z","iopub.status.idle":"2023-10-29T12:05:58.542745Z","shell.execute_reply.started":"2023-10-29T12:05:58.534283Z","shell.execute_reply":"2023-10-29T12:05:58.541782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_training_history(seg_history)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T12:06:02.331642Z","iopub.execute_input":"2023-10-29T12:06:02.332501Z","iopub.status.idle":"2023-10-29T12:06:02.887897Z","shell.execute_reply.started":"2023-10-29T12:06:02.332466Z","shell.execute_reply":"2023-10-29T12:06:02.886927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_training_history(class_history)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T12:06:06.980839Z","iopub.execute_input":"2023-10-29T12:06:06.981218Z","iopub.status.idle":"2023-10-29T12:06:07.583863Z","shell.execute_reply.started":"2023-10-29T12:06:06.981190Z","shell.execute_reply":"2023-10-29T12:06:07.582892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install streamlit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import streamlit as st\n# import matplotlib.pyplot as plt\n# import numpy as np\n# import cv2\n# from keras.models import load_model\n\n# # Load the classification model\n# classification_model = tf.saved_model.load(\"//kaggle/working/classification_model.h5\")\n\n# # Load the segmentation model\n# segmentation_model = tf.saved_model.load(\"//kaggle/working/segmentation_model.h5\")\n\n# # Define a function for displaying test results\n# def display_test(display_list):\n#     plt.figure(figsize=(15, 15))\n#     title = ['Input image', 'Predicted mask']\n#     for i in range(len(display_list)):\n#         plt.subplot(1, len(display_list), i + 1)\n#         plt.title(title[i])\n#         plt.imshow(display_list[i])\n#         plt.axis('off')\n#     st.pyplot()\n\n# def main():\n#     st.title(\"Defect Detection App\")\n#     st.sidebar.title(\"Upload an Image\")\n\n#     uploaded_image = st.sidebar.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n\n#     if uploaded_image is not None:\n#         # Load the image using OpenCV\n#         sample_image = cv2.cvtColor(cv2.imread(uploaded_image), cv2.COLOR_BGR2RGB)\n#         sample_image = cv2.resize(sample_image, (128, 128))\n\n#         # Perform inference\n#         # Segmentation inference\n#         prediction = segmentation_model.predict(sample_image[np.newaxis, ...])[0]\n#         predicted_mask = (prediction > 0.5).astype(np.uint8)\n\n#         # Classification inference\n#         prediction_class = classification_model.predict(sample_image[np.newaxis, ...])[0]\n\n#         # Display the input image and predicted mask\n#         display_test([sample_image, predicted_mask])\n\n#         # Display the defect type based on classification model\n#         defect_type = np.argmax(prediction_class)\n#         st.write(\"Type of defect:\", defect_type)\n\n# if __name__ == '__main__':\n#     main()\n\n    \n\n    \n    \n    \n    \n    \n    \n    \n# !streamlit run steel defect: segmen+classiify.ipynb\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# new_model = tf.keras.models.load_model('model.tf')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#INFERENCE\n\n\n\nimport tensorflow as tf\n\n# Load the classification model\nclassification_model = tf.keras.models.load_model(\"//kaggle/working/classification_model.tf\")\n\n# # Load the classification model\n# from keras.models import load_model\n# classification_model = load_model(\"//kaggle/working/classification_model.h5\")\n\nimport tensorflow as tf\n\n# Load the classification model\nsegmentation_model = tf.keras.models.load_model(\"//kaggle/working/segmentation_model.tf\")\n\n# # Load the segmentation model\n# from keras.models import load_model\n# segmentation_model = load_model(\"//kaggle/working/segmentation_model.h5\")\n\n# Define a function for displaying test results\ndef display_test(display_list):\n    plt.figure(figsize=(15, 15))\n    title = ['Input image', 'Predicted mask']\n    for i in range(len(display_list)):\n        plt.subplot(1, len(display_list), i+1)\n        plt.title(title[i])\n        plt.imshow(display_list[i])\n        plt.axis('off')\n    plt.show()\n\n# Input your own image file\nimage_path = \"/kaggle/input/severstal-steel-defect-detection/test_images/0000f269f.jpg\"\n\ninput_shape = (128,128)\n\n# Load the image using OpenCV\nimport cv2\nsample_image = cv2.imread(image_path)\nsample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\nsample_image = cv2.resize(sample_image, input_shape)\n\n\n# Perform inference\n# Segmentation inference\nprediction = segmentation_model.predict(sample_image[np.newaxis, ...])[0]\npredicted_mask = (prediction > 0.5).astype(np.uint8)\n\n# Classification inference\nprediction_class = classification_model.predict(sample_image[np.newaxis, ...])[0]\n\ndisplay_test([sample_image, predicted_mask])\nprint(\"Type defect: \", np.argmax(prediction_class))\n","metadata":{"execution":{"iopub.status.busy":"2023-10-29T12:07:07.269412Z","iopub.execute_input":"2023-10-29T12:07:07.270084Z","iopub.status.idle":"2023-10-29T12:07:30.194244Z","shell.execute_reply.started":"2023-10-29T12:07:07.270052Z","shell.execute_reply":"2023-10-29T12:07:30.193200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #INFERENCE\n\n# # Load the classification model\n# from keras.models import load_model\n# classification_model = load_model(\"//kaggle/working/classification_model.h5\")\n\n# # Load the segmentation model\n# from keras.models import load_model\n# segmentation_model = load_model(\"//kaggle/working/segmentation_model.h5\")\n\n# # Define a function for displaying test results\n# def display_test(display_list):\n#     plt.figure(figsize=(15, 15))\n#     title = ['Input image', 'Predicted mask']\n#     for i in range(len(display_list)):\n#         plt.subplot(1, len(display_list), i+1)\n#         plt.title(title[i])\n#         plt.imshow(display_list[i])\n#         plt.axis('off')\n#     plt.show()\n\n# # Input your own image file\n# image_path = \"/kaggle/input/severstal-steel-defect-detection/test_images/002451917.jpg\"\n\n# input_shape = (128,128)\n\n# # Load the image using OpenCV\n# import cv2\n# sample_image = cv2.imread(image_path)\n# sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n# sample_image = cv2.resize(sample_image, input_shape)\n\n\n# # Perform inference\n# # Segmentation inference\n# prediction = segmentation_model.predict(sample_image[np.newaxis, ...])[0]\n# predicted_mask = (prediction > 0.5).astype(np.uint8)\n\n# # Classification inference\n# prediction_class = classification_model.predict(sample_image[np.newaxis, ...])[0]\n\n# display_test([sample_image, predicted_mask])\n# print(\"Type defect: \", np.argmax(prediction_class))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}